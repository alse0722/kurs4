site:
    https://habr.com/ru/companies/first/articles/683870/

Что такое балансировка нагрузки Nginx?

Nginx — это высокопроизводительный веб-сервер, который также может использоваться в качестве регулятора нагрузки — это процесс распределения веб-трафика между несколькими серверами с помощью Nginx.

Он гарантирует, что ни один сервер не будет перегружен и что все запросы будут обработаны своевременно. 
Nginx использует различные алгоритмы для определения оптимального распределения трафика, а также может быть настроен для обеспечения отказоустойчивости в случае выхода из строя одного из серверов.

Вы можете использовать либо Nginx open source, либо Nginx Plus для балансировки нагрузки HTTP-трафика на группу серверов.

Лично я использую Nginx open source для настройки своих стабилизаторов нагрузки, и именно его я собираюсь показать вам в этой статье.

Преимущества

Балансировка нагрузки помогает масштабировать приложение, справляясь со скачками трафика без увеличения расходов на облако. 
Она также помогает устранить проблему единой точки отказа. Поскольку нагрузка является распределённой, то в случае сбоя одного из серверов — сервис всё равно продолжит работу.


Настройка Nginx в качестве балансировщика нагрузки

Создадим новый файл конфигурации для балансировщика нагрузки:
    cd /etc/nginx/sites-available/
    sudo nano default

    http {
    upstream app{
        server 10.2.0.100;
        server 10.2.0.101;
        server 10.2.0.102;
    }

    # Этот сервер принимает весь трафик на порт 80 и передает его вышестоящему потоку.
    # Обратите внимание, что имя вышестоящего потока и proxy_pass должны совпадать.

    server {
        listen 80;
        
        server_name mydomain.com;

        location / {
            include proxy_params;
            
            proxy_pass http://app;
            

            proxy_redirect off;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
        }
    }
    }

В файле необходимо определить директиву upstream и server. Upstream определяет, куда Nginx будет передавать запросы после их получения. 
Она содержит IP-адреса группы серверов (бэкенда), на которые могут быть отправлены запросы в зависимости от выбранного метода регулирования нагрузки. 
По умолчанию Nginx использует метод балансировки round-robin для распределения мощности между серверами.

Сегмент server определяет порт 80, через который Nginx будет получать запросы. Он также содержит переменную proxy_pass.

Переменная proxy_pass используется для указания NGINX, куда отправлять получаемый трафик. В данном случае переменная proxy_pass указывает на 3 сервера. 
Это позволяет NGINX направлять получаемый трафик на любой из IP-адресов вышестоящих серверов. Nginx одновременно выступает в роли обратного прокси и балансировщика нагрузки.

Обратный прокси — это сервер, который находится между бэкенд-серверами и перехватывает запросы от клиентов.


Выбор метода балансировки нагрузки

Следующий шаг — определение метода распределения нагрузки. Существует несколько методов, которые мы можем использовать. К ним относятся:

Round Robin

Round Robin — это метод балансировки нагрузки, при котором каждому серверу в кластере предоставляется равная возможность обрабатывать запросы. 
Этот метод часто используется в веб-серверах, где каждый запрос сервера равномерно распределяется между серверами.

Мощность распределяется поочерёдно, что означает, что у каждого сервера будет своё время для выполнения запроса. 
Например, если у вас есть три вышестоящих сервера, A, B и C, то балансировщик нагрузки сначала распределит нагрузку на A, затем на B и, наконец, на C, прежде чем перераспределить нагрузку на A. 
Этот метод довольно прост, но имеет некоторую долю ограничений.

Одно из ограничений заключается в том, что некоторые серверы будут простаивать просто потому, что они будут ждать своей очереди. 
В нашем примере, если A получит задание и выполнит его за секунду, это будет означать, что он будет простаивать до следующего задания. 
По умолчанию для распределения нагрузки между серверами Nginx использует именно метод round robin.

Round Robin с добавлением веса

Чтобы решить проблему простоя серверов, мы можем использовать server weights (серверные веса), чтобы указать Nginx, какие серверы должны иметь наибольший приоритет. 
Weighted Round Robin — один из самых популярных методов балансировки нагрузки, используемых сегодня.

Этот метод предполагает присвоение веса каждому серверу, а затем распределение трафика между серверами на основе этих весов. 
Это гарантирует, что серверы с большей пропускной способностью получат больше трафика, и поможет предотвратить перегрузку какого-либо из серверов.

Этот метод часто используется в сочетании с другими методами, такими как Session Persistence, для обеспечения равномерного распределения мощностей на все серверы. 
Сервер приложения с наибольшим параметром веса будет иметь приоритет (больше трафика) по сравнению с сервером с наименьшим числом (весом).

Для того чтобы включить весовые параметры сервера, нужно обновить конфигурацию Nginx:

    http {
    upstream app{
        server 10.2.0.100 weight=5;
        server 10.2.0.101 weight=3;
        server 10.2.0.102 weight=1;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://app;
        }
    }
    }

Least Connection

Метод наименьшего числа соединений (Least Connection) — это популярная техника, используемая для равномерного распределения рабочей нагрузки между несколькими серверами. 
Метод работает путём маршрутизации каждого нового запроса на соединение — на сервер с наименьшим количеством активных соединений. 
Это гарантирует, что все серверы используются одинаково и ни один из них не перегружен.

    http {
    upstream app{
        least_conn;
        server 10.2.0.100;
        server 10.2.0.101;
        server 10.2.0.102;
    }
    server {
        listen 80;

        location / {
            proxy_pass http://app;
        }
    }
    }

Least Connection с добавлением веса

Данный метод используется для распределения рабочей нагрузки между несколькими вычислительными ресурсами (такими как серверы) с целью оптимизации производительности и минимизации времени отклика. 
Этот метод учитывает количество активных соединений на каждом сервере и присваивает соответствующие веса. 
Целью является распределение рабочей нагрузки таким образом, чтобы сбалансировать нагрузку и минимизировать время отклика.

    http {
    upstream app{
        least_conn;
        server 10.2.0.100 weight=5;
        server 10.2.0.101 weight=4;
        server 10.2.0.102 weight=1;
    }
    server {
        listen 80;

        location / {
            proxy_pass http://app;
        }
    }
    }

IP Hash

Метод балансировки IP Hash использует алгоритм хэширования для определения того, какой сервер должен получить каждый из входящих пакетов. 
Это полезно, когда за одним IP-адресом находится несколько серверов, и вы хотите убедиться, что каждый пакет с IP-адреса клиента направляется на один и тот же сервер. 
Он берёт IP-адрес источника и IP-адрес назначения и создаёт уникальный хэш-ключ. Затем он используется для распределения клиента между определёнными серверами.

Это очень важный момент в случае развёртывания canary. 
Это позволяет нам, разработчикам, выпускать изменения для отдельной части пользователей, чтобы они могли всё протестировать и предоставить отзывы, прежде чем отправлять их в релиз.

Преимущество этого подхода в том, что он может обеспечить более высокую производительность, чем другие методы, такие как round-robin.

    http {
    upstream app{
        ip_hash;
        server 10.2.0.100;
        server 10.2.0.101;
        server 10.2.0.102;
    }
    server {
        listen 80;

        location / {
            proxy_pass http://app;
        }
    }
    }

URL Hash

Регулировка нагрузки URL Hash также использует алгоритм хэширования для определения того, какой сервер получит каждый из запросов на основе URL.

Он также похож на метод балансировки IP Hash, но разница в том, что мы хэшируем конкретные URL, а не IP. 
Это гарантирует, что все запросы равномерно распределяются между серверами, обеспечивая лучшую производительность и надёжность.


Заключение

Балансировка нагрузки — это хороший способ распределения запросов между инстансами приложений. 
Он обеспечивает высокую доступность и гарантирует постоянную работоспособность сервера. 
Использование балансировщика Nginx для распределения нагрузки выгодно ещё и потому, что он служит как обратным прокси, так и балансировщиком нагрузки. 
Он также имеет открытый исходный код, поэтому вы всегда сможете получить от Nginx именно то, что нужно вам. Надеюсь, эта статья помогла вам настроить балансировщик нагрузки Nginx.